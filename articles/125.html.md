---
title: 梶研 [伊達巻成功 & GCN, ST-GCN完全に理解した]
category: kajilab/2024年度/04月
tags: date:2024-04-16
created_at: '2024-04-16T00:09:49+09:00'
updated_at: '2024-04-16T11:28:29+09:00'
published: true
number: 125
---

# 伊達巻成功 & GCN, ST-GCN完全に理解した

## 出席率
- 3年セミナー：??%

## スケジュール
### 短期的な予定
- [ ] mocopi と お料理センシング
    - [x] シーンとランドマークを決める(~2月上旬)
    - [x] SVM で動作判別する
    - [ ] 機械学習を深める
        - [x] 機械学習の手法を知る
        - [x] 使う手法を決める
        - [x] データセットを探す
        - [x] LSTM してみる
        - [x] 主成分分析してみる
        - [x] クラスタリング
        - [ ] 自己相関
    - [ ] お料理センシング
        - [x] お料理でどんな動作があるかを知る
        - [x] レシピを決める
        - [ ] センシングする
        - [ ] ?
    - [ ] 論文書く
    - [ ] 発表
- [ ] BLEビーコンのuuidを書き換えたい
    - [x] 通信内容を読み解く
    - [ ] shellコマンドで通信してみる
    - [ ] 実装してみる
- [ ] BookWorm
    - [x] Pasori と デスクトップアプリを接続する(技術検証)
    - [x] nfc読み込み機能 & 画面を作る
    - [ ] API と連携させる
    - [x] 管理者画面を作る

### 長期的な予定
- ~?月 シーン検知?をする
- ~?月 論文を書く
- ~?月 論文発表したい

## 進捗報告
### 目的
料理中の動作を mocopi を使ってセンシングする。
このデータから最終的に位置推定を行う。
- 一定の区間でどの動作をしているかを当てる (クラス分類)
- 料理の手順を元にシーン検知を補正する
    - 例) 焼く動作 → 卵割る動作 はおかしい
- 位置とシーンを相補的に補正する
    - 例) 冷蔵庫の前で焼く動作 はおかしい

### センシングした
完璧でした
<img width="3024" alt="IMG_6564.jpg (948.1 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/0ff012eb-1371-4c9a-85fd-40a869e4b886.jpg">

生産者の顔
<img width="3024" alt="IMG_6565.jpg (988.8 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/f6bf9c61-f7eb-4070-a71d-f5580b6490d4.jpg">

**フライパン買ってください**
横幅がもう少し広いフライパンが欲しい

### 動作認識
動画からではないサンプルコードが欲しい
https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb

よく分からないけど学習が進んだ
```
# Epoch: 1 | Loss: 0.0359 | Accuracy: 15.0500
# Epoch: 2 | Loss: 0.0345 | Accuracy: 20.2500
# Epoch: 3 | Loss: 0.0338 | Accuracy: 22.5000
# Epoch: 4 | Loss: 0.0327 | Accuracy: 26.2500
# Epoch: 5 | Loss: 0.0312 | Accuracy: 29.1500
# Epoch: 6 | Loss: 0.0298 | Accuracy: 32.5500
# Epoch: 7 | Loss: 0.0285 | Accuracy: 36.1500
# Epoch: 8 | Loss: 0.0265 | Accuracy: 41.6000
# Epoch: 9 | Loss: 0.0237 | Accuracy: 49.0500
...
```
とても時間がかかったので10回目で止めた

グラフを表示してくれた
斜め (縦と横の軸が同じところ) が濃いほど正確ぽい
<img width="557" alt="image.png (35.3 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/8a7f1eaa-65c3-439c-bfac-a24aafb87dbe.png">

### 何をしているか追ってみる
追ってみたけど全く分かりませんでした.

### 一旦GCNの理解を頑張る
<img width="538" alt="image.png (10.8 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/939c108b-92d4-4159-9882-8f4e324b722a.png">

#### 入力値を生成
仮でランダムに生成する
```py
X = np.random.randn(num_node, in_channels) + 1
```

TODO: 動作認識ではこの入力値がどう変わるのか

#### 隣接行列を生成
```py
E = [[0, 1], [0, 2], [0, 4], [1, 2], [2, 3]]
# 向きを考慮しないために逆行列を足す
reversed_E = [[j, i] for [i, j] in E]
new_E = E + reversed_E
A = edge2mat(new_E, num_node)
```

#### 畳み込み
$$
[1,1,1,0,1]
\left[
\begin{array}{c}
v_1 \\\\
v_2 \\\\
v_3 \\\\
v_4 \\\\
v_5 \\\\
\end{array}
\right]
= v_1 + v_2 + v_3 + v_5 
$$

隣接している部分だけ取り出すみたいな

その結果が右側
(左の X はランダムのため変化しています)
<img width="538" alt="image.png (11.6 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/21005019-c2ae-491a-a03f-c48f44a8b51d.png">

ノードによる偏りがある
TODO: なぜ偏りが良くないのか

#### 偏りの解消
平均を使うと多少解消される
$$
\tilde{\mathbf{D}}^{-1}\tilde{\mathbf{A}}\mathbf{X}
$$

<img width="538" alt="image.png (11.6 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/c94bb109-07b0-455a-a73f-53a0d034cfcb.png">

実際は正規化するべき
$$
\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}\mathbf{X}
$$

### もっと調べる
畳み込みは 特定のノード に隣接するノード間でいい感じに計算するぽい
だから 隣接行列 を作って掛け算していた

動作認識において 隣接行列 は 関節間 の接続を入れればいいぽい
入力は...
- 加速度, 角速度をうまい感じに入れる?
- 角速度から骨格の形(関節の角度)を生成して使う?
<img width="759" alt="difference_of_cnn_and_gcn.png (102.9 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/9b2d00fd-fd70-4801-8592-9fc350d65d8b.png">

https://disassemble-channel.com/deep-learning-gcn/

↓ をみた感じ、人を正面から見た時の各関節の座標を持っているぽい
```py
fig, ax = plt.subplots(2, 3, figsize=(16.0, 6.0) )
for i in range(6):
    r = i // 3
    c = i % 3
    # エッジを描画
    for e in E:
        ax[r,c].plot([X[i, e[0], 0], X[i, e[1], 0]], [X[i, e[0], 1], X[i, e[1], 1]], "c")
    # ノードを描画
    ax[r,c].scatter(X[i, :, 0], X[i, :, 1], s=7)
    # その他設定
    ax[r,c].set_xlim([0, width])
    ax[r,c].set_ylim([0, height])
    ax[r,c].set_aspect('equal', 'box')
    ax[r,c].set_xticks([])
    ax[r,c].set_yticks([])
    ax[r,c].invert_yaxis()
```
https://zenn.dev/hash_yuki/articles/3b0f782ccffa54

入力値は、腰(ROOT) を原点とした各関節の座標とする?

### やること
- 伊達巻センシングする
-  BVHの1フレームのデータを入力値として、各関節の座標を出力する関数をいい感じに実装する
- 体の向きをグラフで出せるようにする
- 体の向きから各関節の座標 を修正するようにする
- 前に作成したBVHをPythonで扱う `mcp_persor` は大量のデータに対応できない問題に対処する
    - 必要なフレームだけ読み込むみたいな?


## 進路関係


## 余談
### 歓迎されてきました
下校中
<img width="1024" alt="05648D2E-A88F-429E-8785-6FAD8D1124E3_1_105_c.jpeg (268.5 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/171dc041-7fda-4068-a886-9e100c3aeb42.jpeg">

渋谷
<img width="4032" alt="IMG_6531.JPG (7.1 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/ebb67331-ebaf-4787-a72b-f2012092aa6e.JPG">

下北沢コメダ
<img width="4032" alt="IMG_6533.JPG (3.4 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/fadf6ae8-3a89-45f1-b3cc-6ff15bb78255.JPG">

弊社オフィス
<img width="4032" alt="IMG_6536.JPG (4.8 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/1a448697-15ce-4c33-bf2a-6401ee31ff9b.JPG">

ボザロの聖地
<img width="4032" alt="IMG_6539.JPG (3.0 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/c4590c14-cd7d-412b-b75c-2094156f3bfe.JPG">

セカオワの聖地
<img width="4032" alt="IMG_6541.JPG (3.4 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/2390c054-999b-4e99-badd-b077389f0e51.JPG">

帰宅
<img width="768" alt="1516A0DE-2D2D-4077-9A77-575F06B7E5B4_1_105_c.jpeg (272.7 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/ba2fda31-2a0f-4da2-8eb5-035004219c97.jpeg">

### 歓迎しました
いちねんせいたくさん
<img width="1024" alt="87197624-57D9-42A6-9C5B-055D61904401_1_105_c.jpeg (314.5 kB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/04/16/148142/bbf42c1d-1643-43b9-b388-b864f760a3f3.jpeg">

