---
title: æ¢¶ç ” [ST-GCNåºç« ]
category: kajilab/2024å¹´åº¦/05æœˆ
tags: date:2024-05-21
created_at: '2024-05-15T11:28:37+09:00'
updated_at: '2024-05-21T10:42:13+09:00'
published: true
number: 129
---

# ST-GCNåºç« 

## å‡ºå¸­ç‡
- 3å¹´ã‚»ãƒŸãƒŠãƒ¼ï¼š??%

## ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
### çŸ­æœŸçš„ãªäºˆå®š
- [ ] mocopi ã¨ ãŠæ–™ç†ã‚»ãƒ³ã‚·ãƒ³ã‚°
    - [x] ã‚·ãƒ¼ãƒ³ã¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ±ºã‚ã‚‹(~2æœˆä¸Šæ—¬)
    - [x] SVM ã§å‹•ä½œåˆ¤åˆ¥ã™ã‚‹
    - [x] æ©Ÿæ¢°å­¦ç¿’ã‚’æ·±ã‚ã‚‹
    - [ ] ãŠæ–™ç†ã‚»ãƒ³ã‚·ãƒ³ã‚°
        - [x] ãŠæ–™ç†ã§ã©ã‚“ãªå‹•ä½œãŒã‚ã‚‹ã‹ã‚’çŸ¥ã‚‹
        - [x] ãƒ¬ã‚·ãƒ”ã‚’æ±ºã‚ã‚‹
        - [x] é–¢ç¯€ã‚’3æ¬¡å…ƒåº§æ¨™ã«å¤‰æ›ã™ã‚‹
        - [ ] é–¢ç¯€ã‚’2æ¬¡å…ƒåº§æ¨™ã«å¤‰æ›ã™ã‚‹
        - [x] ST-GCN ã‚’å¤§ä½“ç†è§£
        - [ ] ST-GCN ã§å‹•ä½œæ¨å®š
        - [ ] ä¼Šé”å·»ãã§å‹•ä½œæ¨å®šã™ã‚‹
        - [ ] ãƒ¬ã‚·ãƒ”(æ‰‹é †æ›¸)ã‚’å…ƒã«å‹•ä½œæ¨å®šã‚’è£œã†
    - [ ] è«–æ–‡æ›¸ã
    - [ ] ç™ºè¡¨
- [ ] BookWorm
    - [x] Pasori ã¨ ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚’æ¥ç¶šã™ã‚‹(æŠ€è¡“æ¤œè¨¼)
    - [x] nfcèª­ã¿è¾¼ã¿æ©Ÿèƒ½ & ç”»é¢ã‚’ä½œã‚‹
    - [ ] API ã¨é€£æºã•ã›ã‚‹
    - [x] ç®¡ç†è€…ç”»é¢ã‚’ä½œã‚‹

### é•·æœŸçš„ãªäºˆå®š
- 6æœˆ ç²¾åº¦ã¯ç½®ã„ã¦ãŠãã€å‹•ä½œèªè­˜ã‚’å®Œæˆã•ã›ã‚‹
- 7æœˆ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã¨ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹
- 8æœˆ ä»•ä¸Šã’
- 9æœˆ è«–æ–‡æ›¸ãå§‹ã‚
- 10æœˆæœ« è«–æ–‡æå‡º
- 12æœˆ WiNFå½“æ—¥

## é€²æ—å ±å‘Š
### ç›®çš„
æ–™ç†ä¸­ã®å‹•ä½œã‚’ mocopi ã‚’ä½¿ã£ã¦ã‚»ãƒ³ã‚·ãƒ³ã‚°ã™ã‚‹ã€‚
ã“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€çµ‚çš„ã«ä½ç½®æ¨å®šã‚’è¡Œã†ã€‚
- ä¸€å®šã®åŒºé–“ã§ã©ã®å‹•ä½œã‚’ã—ã¦ã„ã‚‹ã‹ã‚’å½“ã¦ã‚‹ (ã‚¯ãƒ©ã‚¹åˆ†é¡)
- æ–™ç†ã®æ‰‹é †ã‚’å…ƒã«ã‚·ãƒ¼ãƒ³æ¤œçŸ¥ã‚’è£œæ­£ã™ã‚‹
    - ä¾‹) ç„¼ãå‹•ä½œ â†’ åµå‰²ã‚‹å‹•ä½œ ã¯ãŠã‹ã—ã„
- ä½ç½®ã¨ã‚·ãƒ¼ãƒ³ã‚’ç›¸è£œçš„ã«è£œæ­£ã™ã‚‹
    - ä¾‹) å†·è”µåº«ã®å‰ã§ç„¼ãå‹•ä½œ ã¯ãŠã‹ã—ã„

### ç›®æ¨™
12æœˆé ƒã® WiNF ã«å‡ºãŸã„
(10æœˆæœ« è«–æ–‡å®Œæˆ)

---

### ST-GCN ã™ã‚‹
ST-GCNã¨ã¯
éª¨æ ¼ã‹ã‚‰å‹•ä½œèªè­˜ã‚’è¡Œãˆã‚‹æ©Ÿæ¢°å­¦ç¿’ã®æ‰‹æ³•. ã™ã”ã„ã‚„ã¤

[PyTorchå®Ÿè£…ã§ç†è§£ã™ã‚‹ST-GCN](https://zenn.dev/hash_yuki/articles/3b0f782ccffa54) ã‚’å‚è€ƒã«ã—ã‚ˆã†ã¨ã—ãŸãŒã€ã‚¨ãƒ©ãƒ¼åã„ã¦ã¦è©¦ã›ãªã‹ã£ãŸ
[ST-GCNã«ã‚ˆã‚‹å‹•ä½œèªè­˜](https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb) ã‚’å‚è€ƒã«ã™ã‚‹

ã“ã®ã‚³ãƒ¼ãƒ‰ã®å…ƒã«ãªã£ãŸç ”ç©¶: https://arxiv.org/abs/1801.07455

ç•³ã¿è¾¼ã¿ã¨ã¯
å‚è€ƒ: https://zero2one.jp/ai-word/convolution/
https://www.youtube.com/watch?v=CHx6uHnWErY

---

### ç†è§£ã—ã¤ã¤BVHç”¨ã«ç½®ãæ›ãˆã¦è¡Œã

#### ãƒ©ãƒ³ãƒ€ãƒ å€¤ã‚’å›ºå®šã™ã‚‹
ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚åŒã˜çµæœã«ãªã‚‹ã‚‰ã—ã„
ãŸã ã—ã€å‡¦ç†ãŒå°‘ã—é…ããªã‚‹ã‹ã‚‚
```py
seed = 123

np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.backends.cudnn.deterministic = True
torch.use_deterministic_algorithms = True
```

#### ã‚¨ãƒãƒƒã‚¯ã‚µã‚¤ã‚ºã¨ãƒãƒƒãƒã‚µã‚¤ã‚º
ã‚¨ãƒãƒƒã‚¯ã‚µã‚¤ã‚º: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã•ã›ã‚‹å›æ•°
ãƒãƒƒãƒã‚µã‚¤ã‚º: 1å›ã®å­¦ç¿’ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿æ•°

```py
NUM_EPOCH = 100
BATCH_SIZE = 64
```

#### ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
ä½•è€…?
```py
model = ST_GCN(
    num_classes=10,
    in_channels=3,
    t_kernel_size=9,
    hop_size=2,
)
```

#### ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
```py
# ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
class ST_GCN(nn.Module):
    def __init__(self, num_classes, in_channels, t_kernel_size, hop_size):
        super().__init__()

        # èª°?
        graph = Graph(hop_size)
        ...

    def forward(self, x):
        ...
```

#### ã‚°ãƒ©ãƒ•ã‚’å®šç¾©
éª¨æ ¼ã®æƒ…å ±ã‹ã‚‰ã€ã©ã®é–¢ç¯€åŒå£«ãŒæ¥ç¶šã—ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™è¡Œåˆ—ã«å¤‰æ›

ã‚¤ãƒ¡ãƒ¼ã‚¸: 
- è‡ªåˆ†è‡ªèº«ã¯è‡ªåˆ†ã«æ¥ç¶šã—ã¦ã„ã‚‹. 
- `0` ã¨ `1` ã¯æ¥ç¶šã—ã¦ã„ã‚‹
- `2` ã¨ `3` ã¯æ¥ç¶šã—ã¦ã„ã‚‹
- ç„¡æŒ‡å‘ã®ãŸã‚åå¯¾ã‚‚æ¥ç¶šã—ã¦ã„ã‚‹
$$
\begin{bmatrix}
   1, 1, 0, 0 \\\\
    1, 1, 0, 1 \\\\
    0, 0, 1, 0 \\\\
    0, 1, 0, 1
\end{bmatrix}
$$

```py
# éš£æ¥è¡Œåˆ—ã‚’ä½œæˆ
class Graph:
    def __init__(self, hop_size, bvhp):
        skeleton = bvhp.get_skeleton()
        node_num = len(skeleton)
        self.edge = self.__get_edge(bvhp)

        # hopæ•°åˆ†é›¢ã‚ŒãŸé–¢ç¯€ã‚’å–å¾—
        hop_dis = self.__get_hop_distance(self.node_num, self.edge, hop_size)

        # éš£æ¥è¡Œåˆ—ã‚’ä½œæˆ
        self.A = self.__get_adjacency_mat(hop_dis, hop_size)
        
    ...
```

#### STGC_block
ç©ºé–“ã¨æ™‚é–“ã§ç•³ã¿è¾¼ã‚“ã§ãã‚Œã‚‹ã‚„ã¤

```py
class STGC_block(nn.Module):
    def __init__(
        self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5
    ):
        super().__init__()
        # ç©ºé–“ã‚°ãƒ©ãƒ•ã®ç•³ã¿è¾¼ã¿
        self.sgc = SpatialGraphConvolution(
            in_channels=in_channels, out_channels=out_channels, s_kernel_size=A_size[0]
        )

        # é‡è¦ãªã‚¨ãƒƒã‚¸ã‚’å­¦ç¿’ã—ã¦ãã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.M = nn.Parameter(torch.ones(A_size))

        # æ™‚é–“ç•³ã¿è¾¼ã¿
        self.tgc = nn.Sequential(
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Conv2d(
                out_channels,
                out_channels,
                (t_kernel_size, 1),
                (stride, 1),
                ((t_kernel_size - 1) // 2, 0),
            ),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
        )

    def forward(self, x, A):
        # å®Ÿéš›ã«ç•³ã¿è¾¼ã‚€
        x = self.tgc(self.sgc(x, A * self.M))
        return x
```

#### ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©(å†ã€…)
å¹³å‡å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã—ã€é›†ç´„ã™ã‚‹ã“ã¨ã§ç‰¹å¾´é‡ã‚’å‡ºã™
å¤šæ¬¡å…ƒç‰ˆç§»å‹•å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼(æ„è¨³)
https://cvml-expertguide.net/terms/dl/layers/pooling-layer/global-average-pooling/

å…¨çµåˆå±¤: NNã§å…¨ã¦ã®ãƒãƒ¼ãƒ‰ã‚’çµåˆã™ã‚‹å±¤
æœ€çµ‚çš„ã«ã©ã®ãƒ©ãƒ™ãƒ«ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã™ç¢ºç‡ã‚’è¡¨ã™
https://zero2one.jp/ai-word/fully-connected-layer

```py
# ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
class ST_GCN(nn.Module):
    def __init__(self, num_classes, in_channels, t_kernel_size, hop_size):
        ...

        # ç©ºé–“ãƒ»æ™‚é–“ã§ç•³ã¿è¾¼ã‚€ã‚„ã¤. ä½•åº¦ã‚‚ã‚„ã‚‹ç†ç”±ã¯ã‚ã‹ã‚‰ãªã„
        self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)
        self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)
        self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)
        self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)
        self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)
        self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)
        ...

    def forward(self, x):
        # ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒã‚’ãƒªã‚·ã‚§ã‚¤ãƒ—ã—ã¤ã¤, ãƒãƒƒãƒæ­£è¦åŒ–ã‚’è¡Œã„, å…ƒã®æ¬¡å…ƒã«æˆ»ã™
        N, C, T, V = x.size()  # batch, channel, frame, node
        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)
        x = self.bn(x)
        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()

        # ç‰¹å¾´ã‚’æ·±ãã¾ã§å­¦ç¿’ã—ã¦ã„ã‚‹
        x = self.stgc1(x, self.A)
        x = self.stgc2(x, self.A)
        x = self.stgc3(x, self.A)
        x = self.stgc4(x, self.A)
        x = self.stgc5(x, self.A)
        x = self.stgc6(x, self.A)

        # äºˆæ¸¬
        ## å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = F.avg_pool2d(x, x.size()[2:])
        x = x.view(N, -1, 1, 1)

        ## å…¨çµåˆå±¤ã®é©ç”¨
        x = self.fc(x)
        x = x.view(x.size(0), -1)

        return x
```


### ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ(å†)
```py
model = ST_GCN(
    num_classes=10,
    in_channels=3,
    t_kernel_size=9,
    hop_size=2,
    bvhp=bvhp, # Graph ã‚’BVHãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã—ãŸ
)
```

### ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
åˆ¥å: æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
ã‚´ãƒ¼ãƒ«(æå¤±0)ã«ãªã£ã‚Œã‚‹ã‚ˆã†ã«åŠ¹ç‡çš„ã«ãŸã©ã‚Šç€ã‘ã‚‹ã‚ˆã†ã«ã™ã‚‹ã‚„ã¤
https://qiita.com/omiita/items/1735c1d048fe5f611f80

ã„ã‚ã‚“ãªæ‰‹æ³•ãŒã‚ã‚‹ãŒã€ç‰¹ã« SGD ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
```py
# ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’ä½¿ã†
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
```

### èª¤å·®é–¢æ•°
ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’æ¸¬ã‚‹ã‚„ã¤
ã©ã‚Œã ã‘ã®æå¤±ãŒã‚ã‚‹ã‹ã‚’è¨ˆç®—
```py
criterion = torch.nn.CrossEntropyLoss()
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”¨æ„
è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†ã‘ã¦èª­ã¿è¾¼ã‚“ã§ã„ã‚‹
```py
data_loader = dict()
data_loader["train"] = torch.utils.data.DataLoader(
    # èª°?
    dataset=Feeder(data_path="data/train_data.npy", label_path="data/train_label.npy"),
    batch_size=BATCH_SIZE,
    shuffle=True,
)
data_loader["test"] = torch.utils.data.DataLoader(
    dataset=Feeder(data_path="data/test_data.npy", label_path="data/test_label.npy"),
    batch_size=BATCH_SIZE,
    shuffle=False,
)
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å®šç¾©
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®ã‚¯ãƒ©ã‚¹ãŒã‚ã‚‹ [torch.utils.data](https://pytorch.org/docs/stable/data.html#map-style-datasets)
â€»Pytorch ã¯ã¡ã‚ƒã‚“ã¨å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã‚“ã ã»ã†ãŒè‰¯ã•ãã†

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯2ç¨®é¡ã‚ã‚‹
- [map-style datasets: ãƒãƒƒãƒ—ã‚¹ã‚¿ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://pytorch.org/docs/stable/data.html#map-style-datasets)
- [Iterable-style datasets: åå¾©å¯èƒ½ã‚¹ã‚¿ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://pytorch.org/docs/stable/data.html#iterable-style-datasets)

ã“ã‚Œã¯ `map-style datasets`
```py
class Feeder(torch.utils.data.Dataset):
    def __init__(self, data_path, label_path):
        super().__init__()

        # è‰¯ã„æ„Ÿã˜ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
        self.motion_df = self.__load_bvh(bvh_path)
        self.label_df = self.__load_label(label_path)

    # ãƒ‡ãƒ¼ã‚¿ã®æ•°ã‚’è¿”ã™
    def __len__(self):
        return len(self.label)

    # indexç•ªç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    def __getitem__(self, index):
        data = np.array(self.data[index])
        label = self.label[index]

        return data, label
```

### ãƒ¢ãƒ‡ãƒ«ã®ãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®š
ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«ã™ã‚‹
```py
model.train()
```

`eval` ã‚’ä½¿ã†ã¨è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã«ãªã‚‹
```py
model.eval()
```

### å­¦ç¿’ã•ã›ã‚‹
é€†ä¼æ’­: å‡ºåŠ›å±¤ã‹ã‚‰å…¥åŠ›å±¤ã«å‘ã‹ã£ã¦èª¤å·®ã‚’ä¼æ’­ã•ã›ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‹¾é…ã‚’è¨ˆç®—ã™ã‚‹

```py
# ã‚¨ãƒãƒƒã‚¯ã‚’ãƒ«ãƒ¼ãƒ—
for epoch in range(1, NUM_EPOCH + 1):
    correct = 0  # æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    sum_loss = 0 # ç´¯ç©æå¤±ã‚’è¨ˆç®—

    # ãƒŸãƒ‹ãƒãƒƒãƒ(ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã®çµ„ã¿åˆã‚ã›) ã§ãƒ«ãƒ¼ãƒ—
    for batch_idx, (data, label) in enumerate(data_loader["train"]):
        
        # GPU ã«è»¢é€ã™ã‚‹ â€»MacBookã¯ç„¡ç†
        data = data.cuda()
        label = label.cuda()

        # äºˆæ¸¬ã‚’è¡Œã†
        output = model(data)

        # æå¤±ã‚’è¨ˆç®—
        loss = criterion(output, label)
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ ã®å‹¾é…ã‚’åˆæœŸåŒ–
        optimizer.zero_grad()
        
        # é€†ä¼æ’­ã§æå¤±ã‚’è¨ˆç®—
        loss.backward()
        
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
        optimizer.step()

        # ç´¯ç©æå¤±ã«åŠ ç®—
        sum_loss += loss.item()
        
        # äºˆæ¸¬çµæœã‹ã‚‰æ­£è§£æ•°ã‚’å‡ºã™
        _, predict = torch.max(output.data, 1)
        correct += (predict == label).sum().item()

    print(
        "# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}".format(
            epoch,
            sum_loss / len(data_loader["train"].dataset),
            (100.0 * correct / len(data_loader["train"].dataset)),
        )
    )
```

### ãƒ¡ãƒ¢
ã‚‚ã—ã‹ã—ã¦äºŒæ¬¡å…ƒã«è½ã¨ã—è¾¼ã¾ãªãã¦ã‚‚ã§ãã‚‹?

### æ¬¡å›TODO
- ç°¡å˜ãªå‹•ä½œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚‹
    - (ãŠæ–™ç†ã¯ãƒ‡ãƒ¼ã‚¿å–ã‚‹ã®å¤§å¤‰)
- ST-GCNã™ã‚‹
    - ã“ã®ã¾ã¾ã§ã¯ã‚¨ãƒ©ãƒ¼ãŒé »ç™ºã™ã‚‹ã¯ãšãªã®ã§ã€ä¿®æ­£ã—å‹•ãã‚ˆã†ã«ã™ã‚‹
    - ç²¾åº¦ã¯äºŒã®æ¬¡


## é€²è·¯é–¢ä¿‚
æ°—ãŒå‘ã„ãŸã®ã§ã€ã‚†ã‚ã¿ãƒ‘ã‚¹ãƒãƒ¼ãƒˆã«å¿œå‹Ÿã—ã¦ã¿ãŸ
ã‚†ã‚ã¿ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è©¦é¨“ã‚’å—ã‘ã‚Œã‚‹ã‚„ã¤. è…•è©¦ã—ã¨ã—ã¦ã‚„ã£ã¦ã¿ã‚‹
https://hrmos.co/pages/yumemi/jobs/101000000010

## ä½™è«‡
### Matsuriba vol.4 ã«å‚åŠ ã—ãŸ
<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Matsuriba vol.4 ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¾ã—ãŸï¼ï¼ğŸ”¥<br>70åä»¥ä¸Šã®ã”å‚åŠ ã‚’é ‚ã„ã¦ãŠã‚Šã¾ã™ï¼<br> <a href="https://twitter.com/hashtag/%E7%A5%AD%E3%82%8A%E5%A0%B4?src=hash&amp;ref_src=twsrc%5Etfw">#ç¥­ã‚Šå ´</a> <a href="https://t.co/md6SSZYunp">pic.twitter.com/md6SSZYunp</a></p>&mdash; MatsuribaTechğŸ® (@MatsuribaTech) <a href="https://twitter.com/MatsuribaTech/status/1791416048228659673?ref_src=twsrc%5Etfw">May 17, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Ateam Officeã®ãƒˆã‚¤ãƒ¬ã‹ã‚‰ã®çœºã‚ãŒè‰¯ã‹ã£ãŸ

<img width="2016" alt="IMG_6804.JPG (1.1 MB)" src="https://img.esa.io/uploads/production/attachments/21347/2024/05/20/148142/ff32100c-7b76-4310-a918-514b6a0e7394.JPG">


